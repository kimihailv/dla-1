{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lhrn5O-qUYZ"
   },
   "source": [
    "# Import and misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meO-Mp9jiAFC",
    "outputId": "3ce0c838-cd55-4199-e590-2116cd25d35f"
   },
   "outputs": [],
   "source": [
    "!pip install torchaudio==0.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbUpoArCqUYa"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "import dataclasses\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchaudio\n",
    "from IPython import display as display_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "812GwLfqqUYf"
   },
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1DuQIyRqUYf"
   },
   "source": [
    "In this notebook we will implement a model for finding a keyword in a stream.\n",
    "\n",
    "We will implement the version with CRNN because it is easy and improves the model. \n",
    "(from https://www.dropbox.com/s/22ah2ba7dug6pzw/KWS_Attention.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PdhApeEh9pH"
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class TaskConfig:\n",
    "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
    "    batch_size: int = 256\n",
    "    learning_rate: float = 3e-4\n",
    "    weight_decay: float = 1e-5\n",
    "    num_epochs: int = 25\n",
    "    n_mels: int = 40\n",
    "    kernel_size: Tuple[int, int] = (20, 5)\n",
    "    stride: Tuple[int, int] = (8, 2)\n",
    "    hidden_size: int = 128\n",
    "    gru_num_layers: int = 2\n",
    "    bidirectional: bool = False\n",
    "    num_classes: int = 2\n",
    "    sample_rate: int = 16000\n",
    "    device: torch.device = torch.device(\n",
    "        'cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA1gPmE1h9pI"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhDvVqcZh9pI",
    "outputId": "5fb1e87d-51ba-447d-f6b7-058e0360304c"
   },
   "outputs": [],
   "source": [
    "!wget https://gist.githubusercontent.com/Kirili4ik/6ac5c745ff8dad094e9c464c08f66f3e/raw/63daacc17f52a7d90f7f4166a3f5deef62b165db/dataset_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "QKgGdL8jh9pJ",
    "outputId": "faf10e67-60ce-4de9-f97a-39bcc81bfd24"
   },
   "outputs": [],
   "source": [
    "from dataset_utils import DatasetDownloader, TrainDataset\n",
    "\n",
    "dataset_downloader = DatasetDownloader(TaskConfig.keyword)\n",
    "labeled_data, _ = dataset_downloader.generate_labeled_data()\n",
    "\n",
    "labeled_data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUxfDJw1qUYi"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkmkxPWQqUYe"
   },
   "outputs": [],
   "source": [
    "class AugsCreation:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.background_noises = [\n",
    "            'speech_commands/_background_noise_/white_noise.wav',\n",
    "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
    "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
    "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
    "            'speech_commands/_background_noise_/pink_noise.wav',\n",
    "            'speech_commands/_background_noise_/running_tap.wav'\n",
    "        ]\n",
    "\n",
    "    def add_rand_noise(self, audio):\n",
    "\n",
    "        # randomly choose noise\n",
    "        noise_num = torch.randint(low=0, high=len(\n",
    "            self.background_noises), size=(1,)).item()\n",
    "        noise = torchaudio.load(self.background_noises[noise_num])[0].squeeze()\n",
    "\n",
    "        noise_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "        noise_energy = torch.norm(noise)\n",
    "        audio_energy = torch.norm(audio)\n",
    "        alpha = (audio_energy / noise_energy) * \\\n",
    "            torch.pow(10, -noise_level / 20)\n",
    "\n",
    "        start = torch.randint(low=0, high=int(\n",
    "            noise.size(0) - audio.size(0) - 1), size=(1,)).item()\n",
    "        noise_sample = noise[start: start + audio.size(0)]\n",
    "\n",
    "        audio_new = audio + alpha * noise_sample\n",
    "        audio_new.clamp_(-1, 1)\n",
    "        return audio_new\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
    "        augs = [\n",
    "            lambda x: x,\n",
    "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
    "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
    "            lambda x: self.add_rand_noise(x)\n",
    "        ]\n",
    "\n",
    "        return augs[aug_num](wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClWThxyYh9pM"
   },
   "outputs": [],
   "source": [
    "indexes = torch.randperm(len(labeled_data))\n",
    "train_indexes = indexes[:int(len(labeled_data) * 0.8)]\n",
    "val_indexes = indexes[int(len(labeled_data) * 0.8):]\n",
    "\n",
    "train_df = labeled_data.iloc[train_indexes].reset_index(drop=True)\n",
    "val_df = labeled_data.iloc[val_indexes].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDPLht5fqUYe"
   },
   "outputs": [],
   "source": [
    "# Sample is a dict of utt, word and label\n",
    "transform_tr = AugsCreation()\n",
    "train_set = TrainDataset(df=train_df, kw=TaskConfig.keyword, transform=transform_tr)\n",
    "val_set = TrainDataset(df=val_df, kw=TaskConfig.keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vbPDqd6qUYj"
   },
   "source": [
    "### Sampler for oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfnjRKo2qUYj"
   },
   "outputs": [],
   "source": [
    "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
    "\n",
    "def get_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UM8gLmHeqUYj"
   },
   "outputs": [],
   "source": [
    "train_sampler = get_sampler(train_set.df['label'].values)\n",
    "val_sampler = get_sampler(val_set.df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyBqbxp0h9pO"
   },
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        wavs = []\n",
    "        labels = []    \n",
    "\n",
    "        for el in data:\n",
    "            wavs.append(el['utt'])\n",
    "            labels.append(el['label'])\n",
    "\n",
    "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
    "        wavs = pad_sequence(wavs, batch_first=True)    \n",
    "        labels = torch.Tensor(labels).long()\n",
    "        return wavs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8G9xPRVqUYk"
   },
   "source": [
    "###  Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wGBMcQiqUYk"
   },
   "outputs": [],
   "source": [
    "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
    "                          shuffle=False, collate_fn=Collator(),\n",
    "                          sampler=train_sampler)\n",
    "#                           num_workers=2, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
    "                        shuffle=False, collate_fn=Collator(),\n",
    "                        sampler=val_sampler,\n",
    "                        num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTlsn6cpqUYk"
   },
   "source": [
    "### Creating MelSpecs on GPU for speeeed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRXMt6it56fW"
   },
   "outputs": [],
   "source": [
    "class LogMelspec():\n",
    "\n",
    "    def __init__(self, is_train, config):\n",
    "        # with augmentations\n",
    "        if is_train:\n",
    "            self.melspec = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(\n",
    "                    sample_rate=config.sample_rate,  n_mels=config.n_mels),\n",
    "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
    "            ).to(config.device)\n",
    "\n",
    "        # no augmentations\n",
    "        else:\n",
    "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "                sample_rate=config.sample_rate,\n",
    "                n_mels=config.n_mels\n",
    "            ).to(config.device)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # already on device\n",
    "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqkz4_gn8BiF"
   },
   "outputs": [],
   "source": [
    "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
    "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoAxmihY8yxr"
   },
   "source": [
    "### Quality measurment functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euwD1UyuqUYk"
   },
   "outputs": [],
   "source": [
    "# FA - true: 0, model: 1\n",
    "# FR - true: 1, model: 0\n",
    "\n",
    "def count_FA_FR(preds, labels):\n",
    "    FA = torch.sum(preds[labels == 0])\n",
    "    FR = torch.sum(labels[preds == 0])\n",
    "    \n",
    "    # torch.numel - returns total number of elements in tensor\n",
    "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHBUrkT1qUYk"
   },
   "outputs": [],
   "source": [
    "def get_au_fa_fr(probs, labels):\n",
    "    sorted_probs, _ = torch.sort(probs)\n",
    "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "        \n",
    "    FAs, FRs = [], []\n",
    "    for prob in sorted_probs:\n",
    "        preds = (probs >= prob) * 1\n",
    "        FA, FR = count_FA_FR(preds, labels)        \n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "    # plt.plot(FAs, FRs)\n",
    "    # plt.show()\n",
    "\n",
    "    # ~ area under curve using trapezoidal rule\n",
    "    return -np.trapz(FRs, x=FAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcEP5cEZqUYl"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26_QtIlXqUYl"
   },
   "outputs": [],
   "source": [
    "# Pay attention to _groups_ param\n",
    "\n",
    "def SepConv(in_size, out_size, kernel_size, stride, padding=0):\n",
    "    return nn.Sequential(\n",
    "        torch.nn.Conv1d(in_size, in_size, kernel_size[1],\n",
    "                        stride=stride[1], groups=in_size,\n",
    "                        padding=padding),\n",
    "\n",
    "        torch.nn.Conv1d(in_size, out_size, kernel_size=1,\n",
    "                        stride=stride[0], groups=int(in_size / kernel_size[0]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIT6STF_qUYl"
   },
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        self.sepconv = SepConv(in_size=config.n_mels, out_size=config.hidden_size,\n",
    "                               kernel_size=config.kernel_size, stride=config.stride)\n",
    "\n",
    "        self.gru = nn.GRU(input_size=config.hidden_size, hidden_size=config.hidden_size,\n",
    "                          num_layers=config.gru_num_layers,\n",
    "                          dropout=0.1,\n",
    "                          bidirectional=config.bidirectional)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.sepconv(x)\n",
    "\n",
    "        # (BS, hidden, seq_len) ->(seq_len, BS, hidden)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x, hidden = self.gru(x, hidden)\n",
    "        # x : (seq_len, BS, hidden * num_dirs)\n",
    "        # hidden : (num_layers * num_dirs, BS, hidden)\n",
    "\n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHZTwEdyqUYl"
   },
   "outputs": [],
   "source": [
    "class AttnMech(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(AttnMech, self).__init__()\n",
    "\n",
    "        ratio = 2 if config.bidirectional else 1\n",
    "        lin_size = config.hidden_size * ratio\n",
    "\n",
    "        self.Wx_b = nn.Linear(lin_size, lin_size)\n",
    "        self.Vt = nn.Linear(lin_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hiddens, scores=None, return_context=False):\n",
    "        \"\"\"\n",
    "        :param hiddens: output of encoder with shape: (BS, seq_len, hidden * num_dirs)\n",
    "        :param scores: precomputed attention's scores (aka energy), if None then they will be computed\n",
    "        :param return_context: if True then forward will return context vector else the scores will be returned\n",
    "        \"\"\"\n",
    "\n",
    "        if scores is None:\n",
    "            # (BS, seq_len, 1)\n",
    "            scores = self.Vt(torch.tanh(self.Wx_b(hiddens))) \n",
    "        \n",
    "        if not return_context:\n",
    "            return scores\n",
    "\n",
    "        alphas = F.softmax(scores, dim=1)\n",
    "\n",
    "        return (alphas * hiddens).sum(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BkVo6qpqUYm"
   },
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "\n",
    "    def __init__(self, config, CRNN_model, attn_layer):\n",
    "        super(FullModel, self).__init__()\n",
    "\n",
    "        self.CRNN_model = CRNN_model\n",
    "        self.attn_layer = attn_layer\n",
    "\n",
    "        # ll_in_size, ll_out_size = HIDDEN_SIZE * GRU_NUM_DIRS, NUM_CLASSES\n",
    "        # last layer\n",
    "        ratio = 2 if config.bidirectional else 1\n",
    "        self.U = nn.Linear(config.hidden_size * ratio,\n",
    "                           config.num_classes, bias=False)\n",
    "\n",
    "    def forward(self, batch, hidden=None):\n",
    "        output, hidden = self.CRNN_model(batch, hidden)\n",
    "        # output : (seq_len, BS, hidden * num_dirs)\n",
    "        # hidden : (num_layers * num_dirs, BS, hidden)\n",
    "\n",
    "        c = self.attn_layer(output.transpose(1, 0), return_context=True)\n",
    "\n",
    "        return self.U(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmmSFvWaqUYn"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, loader, log_melspec, device):\n",
    "    model.train()\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # run model # with autocast():\n",
    "        logits = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIeRbn4tqUYo"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(model, loader, log_melspec, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_losses, accs, FAs, FRs = [], [], [], []\n",
    "    all_probs, all_labels = [], []\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        output = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        all_probs.append(probs[:, 1].cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        val_losses.append(loss.item())\n",
    "        accs.append(\n",
    "            torch.sum(argmax_probs == labels).item() /  # ???\n",
    "            torch.numel(argmax_probs)\n",
    "        )\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "\n",
    "    # area under FA/FR curve for whole loader\n",
    "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
    "    return au_fa_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpyvKwp0k3IU"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8sVpHNoocgA",
    "outputId": "91f2f178-98a6-448c-be99-80457a76ee4a"
   },
   "outputs": [],
   "source": [
    "CRNN_model = CRNN(TaskConfig)\n",
    "attn_layer = AttnMech(TaskConfig)\n",
    "full_model = FullModel(TaskConfig, CRNN_model, attn_layer)\n",
    "full_model = full_model.to(TaskConfig.device)\n",
    "\n",
    "print(full_model)\n",
    "\n",
    "opt = torch.optim.Adam(full_model.parameters(),\n",
    "                       lr=TaskConfig.learning_rate, weight_decay=TaskConfig.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "32oooz4lqUYo",
    "outputId": "c4fdfc31-03fa-4540-9c03-4d72c6bdf714",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "for n in range(TaskConfig.num_epochs):\n",
    "\n",
    "    train_epoch(full_model, opt, train_loader,\n",
    "                melspec_train, TaskConfig.device)\n",
    "\n",
    "    au_fa_fr = validation(full_model, val_loader,\n",
    "                          melspec_val, TaskConfig.device)\n",
    "    history['val_metric'].append(au_fa_fr)\n",
    "\n",
    "    clear_output()\n",
    "    plt.plot(history['val_metric'])\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print('END OF EPOCH', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t55FUkOGh9pT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
